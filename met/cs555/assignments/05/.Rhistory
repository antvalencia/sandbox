# adjust the process so that standard deviation is at specific rates while the mean remains
# the same mu=11.6 kg.
# What should be standard deviation of the forces so that 99 percent of tablets meet the
# specification?
sd <- 0.155
100 * (pnorm(x_max, mean=mean, sd=sd) - pnorm(x_min, mean=mean, sd=sd))
# 95.44997
# (b) The manufacturer needs that at least 99 percent of the tablets meet the specification.  He can
# adjust the process so that standard deviation is at specific rates while the mean remains
# the same mu=11.6 kg.
# What should be standard deviation of the forces so that 99 percent of tablets meet the
# specification?
sd <- 0.1555
100 * (pnorm(x_max, mean=mean, sd=sd) - pnorm(x_min, mean=mean, sd=sd))
# 95.44997
# (b) The manufacturer needs that at least 99 percent of the tablets meet the specification.  He can
# adjust the process so that standard deviation is at specific rates while the mean remains
# the same mu=11.6 kg.
# What should be standard deviation of the forces so that 99 percent of tablets meet the
# specification?
sd <- 0.1557
100 * (pnorm(x_max, mean=mean, sd=sd) - pnorm(x_min, mean=mean, sd=sd))
# 95.44997
# (b) The manufacturer needs that at least 99 percent of the tablets meet the specification.  He can
# adjust the process so that standard deviation is at specific rates while the mean remains
# the same mu=11.6 kg.
# What should be standard deviation of the forces so that 99 percent of tablets meet the
# specification?
sd <- 0.1553
100 * (pnorm(x_max, mean=mean, sd=sd) - pnorm(x_min, mean=mean, sd=sd))
# 95.44997
# (b) The manufacturer needs that at least 99 percent of the tablets meet the specification.  He can
# adjust the process so that standard deviation is at specific rates while the mean remains
# the same mu=11.6 kg.
# What should be standard deviation of the forces so that 99 percent of tablets meet the
# specification?
sd <- 0.1554
100 * (pnorm(x_max, mean=mean, sd=sd) - pnorm(x_min, mean=mean, sd=sd))
# 95.44997
# (b) The manufacturer needs that at least 99 percent of the tablets meet the specification.  He can
# adjust the process so that standard deviation is at specific rates while the mean remains
# the same mu=11.6 kg.
# What should be standard deviation of the forces so that 99 percent of tablets meet the
# specification?
sd <- 0.1552
100 * (pnorm(x_max, mean=mean, sd=sd) - pnorm(x_min, mean=mean, sd=sd))
# 95.44997
# (b) The manufacturer needs that at least 99 percent of the tablets meet the specification.  He can
# adjust the process so that standard deviation is at specific rates while the mean remains
# the same mu=11.6 kg.
# What should be standard deviation of the forces so that 99 percent of tablets meet the
# specification?
sd <- 0.1553
100 * (pnorm(x_max, mean=mean, sd=sd) - pnorm(x_min, mean=mean, sd=sd))
# 95.44997
# (b) The manufacturer needs that at least 99 percent of the tablets meet the specification.  He can
# adjust the process so that standard deviation is at specific rates while the mean remains
# the same mu=11.6 kg.
# What should be standard deviation of the forces so that 99 percent of tablets meet the
# specification?
sd <- 0.15535
100 * (pnorm(x_max, mean=mean, sd=sd) - pnorm(x_min, mean=mean, sd=sd))
# 95.44997
# (b) The manufacturer needs that at least 99 percent of the tablets meet the specification.  He can
# adjust the process so that standard deviation is at specific rates while the mean remains
# the same mu=11.6 kg.
# What should be standard deviation of the forces so that 99 percent of tablets meet the
# specification?
sd <- 0.15533
100 * (pnorm(x_max, mean=mean, sd=sd) - pnorm(x_min, mean=mean, sd=sd))
# 95.44997
# (b) The manufacturer needs that at least 99 percent of the tablets meet the specification.  He can
# adjust the process so that standard deviation is at specific rates while the mean remains
# the same mu=11.6 kg.
# What should be standard deviation of the forces so that 99 percent of tablets meet the
# specification?
sd <- 0.15531
100 * (pnorm(x_max, mean=mean, sd=sd) - pnorm(x_min, mean=mean, sd=sd))
# 95.44997
# (b) The manufacturer needs that at least 99 percent of the tablets meet the specification.  He can
# adjust the process so that standard deviation is at specific rates while the mean remains
# the same mu=11.6 kg.
# What should be standard deviation of the forces so that 99 percent of tablets meet the
# specification?
sd <- 0.15530
100 * (pnorm(x_max, mean=mean, sd=sd) - pnorm(x_min, mean=mean, sd=sd))
# Describe your solution: (10 points)
0.4/2.576
# Describe your solution: (10 points)
(0.4/2.576)*sqrt(30)
# Describe your solution: (10 points)
(0.4/2.576)*sqrt(300)
# Describe your solution: (10 points)
(0.4/2.576)*sqrt(1)
# 95.44997
# (b) The manufacturer needs that at least 99 percent of the tablets meet the specification.  He can
# adjust the process so that standard deviation is at specific rates while the mean remains
# the same mu=11.6 kg.
# What should be standard deviation of the forces so that 99 percent of tablets meet the
# specification?
sd <- 0.1552795
100 * (pnorm(x_max, mean=mean, sd=sd) - pnorm(x_min, mean=mean, sd=sd))
# Describe your solution: (10 points)
(0.4/2.576)*sqrt(1)
# Describe your solution: (10 points)
(0.4/2.576)*sqrt(1.5)
# 95.44997
# (b) The manufacturer needs that at least 99 percent of the tablets meet the specification.  He can
# adjust the process so that standard deviation is at specific rates while the mean remains
# the same mu=11.6 kg.
# What should be standard deviation of the forces so that 99 percent of tablets meet the
# specification?
# Confidence level is 99%, so z = 2.576
qnorm(99)
# 95.44997
# (b) The manufacturer needs that at least 99 percent of the tablets meet the specification.  He can
# adjust the process so that standard deviation is at specific rates while the mean remains
# the same mu=11.6 kg.
# What should be standard deviation of the forces so that 99 percent of tablets meet the
# specification?
# Confidence level is 99%, so z = 2.576
qnorm(.99)
# 95.44997
# (b) The manufacturer needs that at least 99 percent of the tablets meet the specification.  He can
# adjust the process so that standard deviation is at specific rates while the mean remains
# the same mu=11.6 kg.
# What should be standard deviation of the forces so that 99 percent of tablets meet the
# specification?
# Confidence level is 99%, so z = 2.576
qnorm(.99, mean=11.6)
# Describe your solution: (10 points)
(12.0-11.6)/2.576
# Describe your solution: (10 points)
(11.6-11.2)/2.576
sd <- 0.1552795
100 * (pnorm(x_max, mean=mean, sd=sd) - pnorm(x_min, mean=mean, sd=sd))
x_bar_s <- 104.12
s_s <- 14.60
n_s <- 57
x_bar_ns <- 97.82
s_ns <- 14.20
n_ns <- 18
t <- (x_bar_s - x_bar_ns)/sqrt((s_s^2/n_s) + (s_ns^2/n_ns))
t
# We have data on the lean body mass and resting metabolic rate for 10 women who are subjects
# in a study on dieting.  Lean body mass, given in kilograms, is a person's weight leaving out all
# fat.  Metabolic rate, in calories burned per 24 hours, is the rate at which the body consumes
# energy.
#
# ---------------------------------------------------------------------------------------
# Mass  | 35.2  | 54.6  | 48.5  | 42.0  | 50.6  | 42.0  | 40.3  | 33.1  | 42.4  | 34.5  |
# Rate  | 991   | 1455  | 1395  | 1418  | 1502  | 1246  | 1189  | 913   | 1124  | 1052  |
# ---------------------------------------------------------------------------------------
#
mass <- c(35.2,54.6,48.5,42.0,50.6,42.0,40.3,33.1,42.4,34.5)
rate <- c(991,1455,1395,1418,1502,1246,1189,913,1124,1052)
# (a) Find the least-squares regression line for predicting metabolic rate from body mass.
lm(rate~mass)
# Beta_0 = 115.80
# Beta_1 = 26.29
beta_0 <- 115.80
beta_1 <- 26.29
# (b) Another woman has lean body mass 48 kilograms.  What is her predicted metabolic rate?
x <- 48
beta_0 + beta_1*x
# ,,,,317034.3229,,72526.24893
# ---------------------------------------------------------------------------------
#             | SS           |  df               |  MS                            |
# ---------------------------------------------------------------------------------
# Regression  | 317034.3229  |  k=1              |  317034.3229/1=317034.3229     |
# Residual    | 72526.24893  |  n-k-1=10-1-1=8   |  72526.24893/8=9065.78111625   |
# ---------------------------------------------------------------------------------
# Total       | 389560.5719  |                 |                                |
# ---------------------------------------------------------------------------------
# R^2 = reg_ss/total_ss
317034.3229/389560.5719
# Q10 (20 points) ???????????????????????????????????????????????????????????????????????????
# A research studied the correlation between physical characteristics of sisters and brothers.
# Here are data on the heights (in inches) of 11 adult pairs.
# -----------------------------------------------------------------------------
# Brother  |  71  | 69  | 66  | 67  | 70  | 71  | 70  | 73  | 72  | 65  | 66  |
# Sister   |  69  | 63  | 65  | 63  | 65  | 62  | 65  | 64  | 66  | 59  | 62  |
# -----------------------------------------------------------------------------
# (a) Find the correlation and the equation of the least-squares line for predicting sister's height
# from brother's height.
brother <- c(71,69,66,67,70,71,70,73,72,65,66)
sister <- c(69,63,65,63,65,62,65,64,66,59,62)
r <- cor(brother,sister)
r
# r = 0.5596833
lm(sister~brother)
mass <- c(35.2,54.6,48.5,42.0,50.6,42.0,40.3,33.1,42.4,34.5)
rate <- c(991,1455,1395,1418,1502,1246,1189,913,1124,1052)
# (a) Find the least-squares regression line for predicting metabolic rate from body mass.
lm(rate~mass)
# Q10 (20 points) ???????????????????????????????????????????????????????????????????????????
# A research studied the correlation between physical characteristics of sisters and brothers.
# Here are data on the heights (in inches) of 11 adult pairs.
# -----------------------------------------------------------------------------
# Brother  |  71  | 69  | 66  | 67  | 70  | 71  | 70  | 73  | 72  | 65  | 66  |
# Sister   |  69  | 63  | 65  | 63  | 65  | 62  | 65  | 64  | 66  | 59  | 62  |
# -----------------------------------------------------------------------------
# (a) Find the correlation and the equation of the least-squares line for predicting sister's height
# from brother's height.
brother <- c(71,69,66,67,70,71,70,73,72,65,66)
sister <- c(69,63,65,63,65,62,65,64,66,59,62)
r <- cor(brother,sister)
# r = 0.5596833
lm(sister~brother)
# equation for the least-squares regression line for predicting sister's height from brother's
# is:   y = 26.8653 + 0.5362*x
#
# (b) Carlos is 72 inches tall.  Predict the height of his sister.
x <- 72
26.8653 + 0.5362*x
# y = 65.4717 inches
#
# (c) Based on the scatterplot and the correlation r, do you expect your prediction to be very
# accurate?  Why?
plot(brother, sister)
# Q10 (20 points) ???????????????????????????????????????????????????????????????????????????
# A research studied the correlation between physical characteristics of sisters and brothers.
# Here are data on the heights (in inches) of 11 adult pairs.
# -----------------------------------------------------------------------------
# Brother  |  71  | 69  | 66  | 67  | 70  | 71  | 70  | 73  | 72  | 65  | 66  |
# Sister   |  69  | 63  | 65  | 63  | 65  | 62  | 65  | 64  | 66  | 59  | 62  |
# -----------------------------------------------------------------------------
# (a) Find the correlation and the equation of the least-squares line for predicting sister's height
# from brother's height.
brother <- c(71,69,66,67,70,71,70,73,72,65,66)
sister <- c(69,63,65,63,65,62,65,64,66,59,62)
r <- cor(brother,sister)
# r = 0.5596833
lm(sister~brother)
# Beta_0 = 26.8653
# Beta_1 = 0.5362
beta_0 <- 26.8653
beta_1 <- 0.5362
# equation for the least-squares regression line for predicting sister's height from brother's
# is:   y = 26.8653 + 0.5362*x
#
# (b) Carlos is 72 inches tall.  Predict the height of his sister.
x <- 72
y <- 26.8653 + 0.5362*x
# y = 65.4717 inches
#
# (c) Based on the scatterplot and the correlation r, do you expect your prediction to be very
# accurate?  Why?
plot(brother, sister)
# scatterplot shows a positive relationship and a positive slope.  with r = 0.5596833, which is
# much closer to 1 than -1, this confirms the positive slope.  Though, because the correlation is
# not closer to the value of 1, I would claim that the prediction is somewhat accurate.  There is
# a significant trend, so there is definitely a degree of accuracy to the prediction.  However,
# I would hesitate to go as far as to claim it is very accurate.
#
# (d) Is there evidence of a significant linear association between physical characteristics of
# sisters and brothers (alpha = 0.05 level)?
n <-
t = r*sqrt((n-2)/(1-r^2))
# scatterplot shows a positive relationship and a positive slope.  with r = 0.5596833, which is
# much closer to 1 than -1, this confirms the positive slope.  Though, because the correlation is
# not closer to the value of 1, I would claim that the prediction is somewhat accurate.  There is
# a significant trend, so there is definitely a degree of accuracy to the prediction.  However,
# I would hesitate to go as far as to claim it is very accurate.
#
# (d) Is there evidence of a significant linear association between physical characteristics of
# sisters and brothers (alpha = 0.05 level)?
n <- length(brother)
t = r*sqrt((n-2)/(1-r^2))
df <- n - 2
# H0:ρ=0 (there is no linear association)
# H1:ρ≠0 (there is a linear association)
# alpha=0.05
# 2
# t = r*sqrt((n-2)/(1-r^2))
# 3
# Decision Rule: Reject H0 if p<alpha. Otherwise do not reject H0.
# Determine the appropriate value from the t-distribution table with n−2=11−2=9
# degrees of freedom and associated with a right hand tail probability of alpha/2=0.025
# Using the table, t=2.045
qt(0.975, df=9)
# 1
# H0:ρ=0 (there is no linear association)
# H1:ρ≠0 (there is a linear association)
# alpha=0.05
# 2
# t = r*sqrt((n-2)/(1-r^2))
# 3
# Determine the appropriate value from the t-distribution table with n−2=11−2=9
# degrees of freedom and associated with a right hand tail probability of alpha/2=0.025
# Using the table, t=2.262157
n <- length(brother)
qt(0.975, df=n)
qt(0.975, df=n-2)
# 1
# H0:ρ=0 (there is no linear association)
# H1:ρ≠0 (there is a linear association)
# alpha=0.05
# 2
# t = r*sqrt((n-2)/(1-r^2))
# 3
# Determine the appropriate value from the t-distribution table with n−2=11−2=9
# degrees of freedom and associated with a right hand tail probability of alpha/2=0.025
# Using the table, t=2.262157
n <- length(brother)
df <- n-2
qt(0.975, df=df)
# Decision Rule: Reject H0 if t≥2.262157 or if t≤−2.262157 (|t|≥2.262157).
# Otherwise, do not reject H0
# 4
# 5
t = r*sqrt((df)/(1-r^2))
t
library(plyr)
setwd("/Users/anthony.valencia/met/cs555/assignments/05/")
# (1)	How many students are in each group?  Summarize the data relating to both test
# score and age by the student group (separately).  Use appropriate numerical and/or
# graphical summaries.  (3 points)
students <- read.csv("students.csv")
boxplot(iq~group, data=students, main="Students IQ", xlab="major", ylab="IQ")
tapply(students$iq, students$group, summary)
# Chemistry
# Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
# 40.00   44.00   46.00   46.27   48.00   52.00
#
# Math
# Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
# 24.0    36.0    38.0    37.6    40.5    45.0
#
# Physics
# Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
# 25.00   31.50   34.00   34.13   37.50   42.00
boxplot(age~group, data=students, main="Students Age", xlab="major", ylab="age")
tapply(students$age, students$group, summary)
library(plyr)
setwd("/Users/anthony.valencia/met/cs555/assignments/05/")
students <- read.csv("students.csv")
# (1)	How many students are in each group?  Summarize the data relating to both test
# score and age by the student group (separately).  Use appropriate numerical and/or
# graphical summaries.  (3 points)
table(students$group)
# Chemistry: 15
# Math: 15
# Physics: 15
boxplot(iq~group, data=students, main="Students IQ", xlab="major", ylab="IQ")
tapply(students$iq, students$group, summary)
# Chemistry
# Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
# 40.00   44.00   46.00   46.27   48.00   52.00
#
# Math
# Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
# 24.0    36.0    38.0    37.6    40.5    45.0
#
# Physics
# Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
# 25.00   31.50   34.00   34.13   37.50   42.00
boxplot(age~group, data=students, main="Students Age", xlab="major", ylab="age")
tapply(students$age, students$group, summary)
# Chemistry
# Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
# 32.00   38.00   41.00   40.07   43.00   46.00
#
# Math
# Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
# 16.00   19.00   20.00   20.73   22.50   28.00
#
# Physics
# Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
# 14.00   16.00   17.00   17.13   18.50   20.00
# (2)	Do the test scores vary by student group?  Perform a one way ANOVA using the
# aov or Anova function in R to assess.  Summarize the results using the 5 step
# procedure.  If the results of the overall model are significant, perform the
# appropriate pairwise comparisons using Tukey’s procedure to adjust for multiple
# comparisons and summarize these results.  (7 points)
n <- nrow(students)
k <- ncol(students)
a <- 0.05
# 1 (Set up hypothesis and select alpha level)
# h0: uc = um = up (all underlying population IQ score means are equal)
# h1: ui != uj for some i and j  (not all of the underlying population IQ score means are equal)
#
# 2 (Select appropriate test statistic)
# F = MSB/MSW with k-1=2 and n-k=42 degrees of freedom
df1 <- k-1
df2 <- n-k
#
# 3 (State the decision rule)
# F-distribution with 2,42 degrees of freedom and associated with a=0.05
qf(1-a, df1=df1, df2=df2)
# F(2,42,0.05)=3.219942
# Decision Rule: Reject h0 if F>=3.219942
# Otherwise, do not reject h0
#
# 4 (Compute the test statistic)
x.bar <- sum(students$iq)/length(students$iq)
students.math <- students[students$group=='Math student', ]
students.math.n <- nrow(students.math)
students.math.iq <- students.math$iq
x.math.bar <- sum(students.math.iq)/students.math.n
students.math.iq.sqrd <- students.math.n*((x.math.bar-x.bar)^2)
students.chemistry <- students[students$group=='Chemistry student', ]
students.chemistry.n <- nrow(students.chemistry)
students.chemistry.iq <- students.chemistry$iq
x.chemistry.bar <- sum(students.chemistry.iq)/students.chemistry.n
students.chemistry.iq.sqrd <- students.chemistry.n*((x.chemistry.bar-x.bar)^2)
students.physics <- students[students$group=='Physics student', ]
students.physics.n <- nrow(students.physics)
students.physics.iq <- students.physics$iq
x.physics.bar <- sum(students.physics.iq)/students.physics.n
students.physics.iq.sqrd <- students.physics.n*((x.physics.bar-x.bar)^2)
ssb <- sum(students.math.iq.sqrd) +
sum(students.chemistry.iq.sqrd) +
sum(students.physics.iq.sqrd)
msb <- ssb/df1
# msb=585.8667
ssw <- sum((students.math.iq-x.math.bar)^2) +
sum((students.chemistry.iq-x.chemistry.bar)^2) +
sum((students.physics.iq-x.physics.bar)^2)
msw <- ssw/df2
# msw=22.05397
f <- msb/msw
f
# f=26.56514
m <- aov(students$iq~students$group, data=students)
summary(m)
#
# 5 (Conclusion)
# reject h0 (all underlying population IQ score means are equal) since 26.56514>=3.219942.
# Therefore, the test is significant.
is.factor(students$group)
aggregate(students$iq, by=list(students$group), summary)
aggregate(students$iq, by=list(students$group), sd)
boxplot(students$iq~students$group, data=students, main="IQ by Major")
pairwise.t.test(students$iq, students$group, p.adj="bonferroni")
# Chemistry/Math: 2.7e-05
# Math/Physics: 0.15
# Chemistry/Physics: 3.4e-08
TukeyHSD(m)
#                                     diff        lwr        upr     p adj
# Math student-Chemistry student     -8.666667 -12.832756 -4.5005778 0.0000262
# Physics student-Chemistry student -12.133333 -16.299422 -7.9672445 0.0000000
# Physics student-Math student       -3.466667  -7.632756  0.6994222 0.1194835
# (3)	Create an appropriate number of dummy variables for student group and re-run
# the one-way ANOVA using the lm function with the newly created dummy variables.
# Set chemistry students as the reference group.  Confirm if the results are the same.
# What is the interpretation of the beta estimates from the regression model?  (4 points)
students$dummy.m <- ifelse(students$group=='Math student',1,0)
students$dummy.c <- ifelse(students$group=='Chemistry student',1,0)
students$dummy.p <- ifelse(students$group=='Physics student',1,0)
m.c <- lm(iq~dummy.m+dummy.p, data=students)
summary(m.c)
#l:
#  lm(formula = iq ~ dummy.m + dummy.p, data = students)
#
#Residuals:
#  Min       1Q   Median       3Q      Max
#-13.6000  -2.1333  -0.1333   2.7333   7.8667
#
#Coefficients:
#              Estimate Std. Error t value Pr(>|t|)
#(Intercept)     46.267      1.213  38.157  < 2e-16 ***
#  dummy.m       -8.667      1.715  -5.054 8.93e-06 ***
#  dummy.p      -12.133      1.715  -7.076 1.13e-08 ***
#  ---
#  Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
#
#Residual standard error: 4.696 on 42 degrees of freedom
#Multiple R-squared:  0.5585,	Adjusted R-squared:  0.5375
#F-statistic: 26.57 on 2 and 42 DF,  p-value: 3.496e-08
# f-statistic is 26.57 vs 26.56514 as calculated above. So, results are the same.
# y_hat = 46.267 - 8.667*group.m - 12.133*group.p
# math group performs negatively (-8.667) with respect to reference (chemistry) group
# physics group performs even more negatively (-12.133) than math group with respect to reference (chemistry) group
# (4)	Re-do the one-way ANOVA adjusting for age.   Focus on the output relating to the
# comparisons of test score by student type.  Explain how this analysis differs from the
# analysis in step 2 above (not the results but how does this analysis differ in terms
# of the questions it answers as opposed to the one above).  Did you obtain different
# results?  Summarize briefly (no need to go through the 5 –step procedure here).
# Present the least square means and interpret these. (6 points)
# install.packages('car')
library(car)
Anova(lm(students$iq~students$group+students$age), type=3)
# Anova Table (Type III tests)
#
# Response: students$iq
#                Sum Sq Df F value   Pr(>F)
# (Intercept)    152.74  1  7.8294 0.007797 **
# students$group  21.89  2  0.5610 0.574969
# students$age   126.42  1  6.4804 0.014763 *
# Residuals      799.84 41
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# install.packages('lsmeans')
library(lsmeans)
options(contrasts=c("contr.treatment", "contr.poly"))
lsmeans(lm(students$iq~students$group+students$age), pairwise~students$group, adjust="none")
# $lsmeans
# students$group      lsmean       SE df lower.CL upper.CL
# Chemistry student 32.96513 1.229289 41 30.48253 35.44773
# Math student      34.06032 1.140782 41 31.75646 36.36418
# Physics student   32.96513 1.229289 41 30.48253 35.44773
#
# Confidence level used: 0.95
#
# $contrasts
# contrast                             estimate        SE df t.ratio p.value
# Chemistry student - Math student    -1.095193 0.4302201 41  -2.546  0.0148
# Chemistry student - Physics student  0.000000 0.0000000 41     NaN     NaN
# Math student - Physics student       1.095193 0.4302201 41   2.546  0.0148
m <- aov(students$iq~students$group, data=students)
summary(m)
